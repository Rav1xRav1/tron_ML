    def play(self):
        """
        ゲームを一試合プレイする
        """
        done = False  # True: 試合終了 False: 試合継続

        while not done:
            if self.env.check_turn() == self.env.one_client_koma:
                states = np.array([self.env.get_board_info()])  # ボード情報をndarrayに変換

                reward = 0  # 報酬
                terminal = False  # 終了判定
                action = None  # 次の手

                # すでにゲームが終わっていないか確認する
                if self.env.can_move():  # 自分自身が動けるか
                    action = self.brian.get_action(states)  # 次の一手を決定する
                    print("one action:", action)

                    if self.env.put_one_koma(action=action):
                        # self.env.print_board()
                        print("AI loss")
                        self.brain.train(np.concatenate([self.env.memorize_game_board, ]))
                else:  # False: 動けない
                    reward = -1
                    terminal = True
                    self.brain.train(np.concatenate([states, np.array([[self.env.one_posi]])], 1),
                                     np.concatenate([np.array([self.env.get_memorize_board_info()]),
                                                     np.array([[self.env.one_posi]])], 1), action, -1, terminal)

                # 今の場面で「action」方向に移動できるなら移動先の座標を返す.不可なら同じ座標を返す
                can, next_position = self.env.can_put(self.env.one_posi, action)

                # もしも「action」方向に駒が置けないのなら
                if next_position == self.env.one_posi:
                    self.brain.train(np.concatenate([states, np.array([[action]])], 1),
                                     np.concatenate([states, np.array([[action]])], 1), action, -0.2, terminal)
                # 置けるなら変数に代入する
                else:
                    self.env.one_posi = next_position

                    self.env.game_board[self.env.one_posi] = self.env.one_client_koma  # 盤に自分の駒を配置する

                    next_states = np.array([self.env.game_board])
                    self.brain.train(np.concatenate([states, np.array([[action]])], 1),
                                     np.concatenate([next_states, np.array([[action]])], 1), action, reward, terminal)

            else:
                self.env.memorize_game_board = np.array([self.env.get_board_info()])
